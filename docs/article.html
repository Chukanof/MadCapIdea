<h1>Introduction</h1>
<p>This article is the culmination of stuff I have been doing on the train on my 
way to work over 6 months. I have written quite a lot of blog posts on this 
already which you can read about on the projects home page on my blog :
<a href="https://sachabarbs.wordpress.com/2017/05/01/madcap-idea/" target="_blank">
https://sachabarbs.wordpress.com/2017/05/01/madcap-idea/</a> </p>
<p>There are 13 blog posts there, but I thought it would be good to also have 
this overall article which covers all of it, as the blog posts are more a 
sequence of events that I went through which talk about the peices in great 
detail as I went through them</p>
<p>For example these were the blog posts</p>
<ul>
	<li>
	<a href="https://sachabarbs.wordpress.com/2017/05/15/madcap-idea-part-1-start-of-the-client-side-portion-of-the-web-site/" target="_blank">
	MADCAP IDEA PART 1 : START OF THE CLIENT SIDE PORTION OF THE WEB SITE</a></li>
	<li>
	<a href="https://sachabarbs.wordpress.com/2017/05/23/madcap-idea-part-2-adding-diioc-to-the-client-side-front-end-web-site/" target="_blank">
	MADCAP IDEA PART 2 : ADDING DI/IOC TO THE CLIENT SIDE FRONT END WEB SITE</a></li>
	<li>
	<a href="https://sachabarbs.wordpress.com/2017/06/07/madcap-idea-part-3-bringing-play-back-end-into-the-fold-some-basic-streaming-2/" target="_blank">
	MADCAP IDEA PART 3 : BRINGING PLAY BACK END INTO THE FOLD + SOME BASIC 
	STREAMING</a></li>
	<li>
	<a href="https://sachabarbs.wordpress.com/2017/06/07/madcap-idea-part-4-prototyping-the-screens/" target="_blank">
	MADCAP IDEA PART 4 : PROTOTYPING THE SCREENS</a></li>
	<li>
	<a href="https://sachabarbs.wordpress.com/2017/06/13/madcap-idea-part-5-adding-react-router/" target="_blank">
	MADCAP IDEA PART 5 : ADDING REACT-ROUTER</a></li>
	<li>
	<a href="https://sachabarbs.wordpress.com/2017/06/27/madcap-idea-part-6-static-screen-design/" target="_blank">
	MADCAP IDEA PART 6 : STATIC SCREEN DESIGN</a></li>
	<li>
	<a href="https://sachabarbs.wordpress.com/2017/08/01/madcap-idea-part-7-registrationlogin-backend/" target="_blank">
	MADCAP IDEA PART 7 : REGISTRATION/LOGIN BACKEND</a></li>
	<li>
	<a href="https://sachabarbs.wordpress.com/2017/09/01/madcap-idea-part-8-intermediate-step-rest-api-for-interactive-kafka-stream-ktable-queries/" target="_blank">
	MADCAP IDEA PART 8 : INTERMEDIATE STEP, REST API FOR INTERACTIVE KAFKA 
	STREAM KTABLE QUERIES</a></li>
	<li>
	<a href="https://sachabarbs.wordpress.com/2017/09/11/madcap-idea-9-kafka-streams-interactive-queries/" target="_blank">
	MADCAP IDEA 9 : KAFKA STREAMS INTERACTIVE QUERIES</a></li>
	<li>
	<a href="https://sachabarbs.wordpress.com/2017/09/21/madcap-idea-10-play-framework-reactive-kafka-producer/" target="_blank">
	MADCAP IDEA 10 : PLAY FRAMEWORK REACTIVE KAFKA PRODUCER</a></li>
	<li>
	<a href="https://sachabarbs.wordpress.com/2017/09/28/madcap-idea-11-finishing-the-view-rating-page/" target="_blank">
	MADCAP IDEA 11 : FINISHING THE ‘VIEW RATING’ PAGE</a></li>
	<li>
	<a href="https://sachabarbs.wordpress.com/2017/10/24/madcap-idea-12-getting-the-create-job-to-work-end-end/" target="_blank">
		MADCAP IDEA 12 : GETTING THE ‘CREATE JOB’ TO WORK END–END</a></li>
	<li>
	<a href="https://sachabarbs.wordpress.com/2017/11/23/madcap-idea-13-getting-the-view-job-to-work-end-end/" target="_blank">
	MADCAP IDEA 13 : GETTING THE ‘VIEW JOB’ TO WORK END-END</a></li>
</ul>
<p>&nbsp;</p>
<h2>So just exactly what is it that I was/am talking about?</h2>
<p>In essence I want to write a very (pardon the pun) but uber simple “uber” 
type app. Where there are the following funtional requirements<br><br></p>
<ul>
	<li>There should be a web interface that a client can use. Clients may be a 
	“driver” or a “pickup client” requireing a delivery</li>
	<li>There should be a web interface that a “pickup client” can use, that 
	shows a “pickup client” location on a map, which the “pickup client” choses.</li>
	<li>The “pickup client” may request a pickup job, in which case “drivers” 
	that are in the area bid for a job.</li>
	<li>The “pickup client” location should be visible to a “driver” on a map</li>
	<li>A “driver” may bid for a “pickup client” job, and the bidding 
	“driver(s)” location should be visible to the “pickup client”.</li>
	<li>The acceptance of the bidding “driver” is down to the “pickup client”</li>
	<li>Once a “pickup client” accepts a “driver” ONLY the assigned “driver(s)” 
	current map position will be shown to the “pickup client”</li>
	<li>When a “pickup client” is happy that they have been picked up by a 
	“driver”, the “pickup client” may rate the driver from 1-10, and the 
	“driver” may also rate the “pickup client” from 1-10.</li>
	<li>The rating should only be available once a “pickup client” has marked a 
	job as “completed”</li>
	<li>A “driver” or a “pickup client” should ALWAYS be able to view their 
	previous ratings. </li>
</ul>
<p>Whilst this may sound child’s play to a lot of you (me included if I 
stuck to using simply CRUD operations), I just want to point out that this 
app is meant as a learning experience so I will not be using a simple 
SignalR Hub, and a couple of database tables.</p>
<p>I have written this proj using a completely different set of technologies from the norm. Some 
of the technology choices could easily scale to hundreds of thousands of 
requests per second (Kafka has your back here)<br><br><strong>TECNHOLOGIES 
INVOLVED</strong></p>
<ul>
	<li>WebPack</li>
	<li>React Router</li>
	<li>TypeScript</li>
	<li>Babel.js</li>
	<li>Akka</li>
	<li>Scala</li>
	<li>Play (Scala Http Stack)</li>
	<li>MongoDB</li>
	<li>SBT</li>
	<li>Kafka</li>
	<li>Kafka Streams</li>
</ul>
<p>They say a picture says a 1000nd words, so here is a nice picture to get 
things started</p>
<p><img alt="" height="565" src="overviewSmall.png" width="630"></p>
<p>Now before we carry on, lety me just acknowledge that
<a href="http://www.codeproject.com">www.codeproject.com</a> is mainly a 
Microsoft set of articles, and this code is mainly scala/typescript I think 
there is still plenty to learn along the way, so dont let the fact its not 
.NET/C/C++ put you off</p>
<p>&nbsp;</p>
<h1>Where is the code?</h1>
<p>The code for all of this lot is here :
<a href="https://github.com/sachabarber/MadCapIdea" target="_blank">
https://github.com/sachabarber/MadCapIdea</a></p>
<h1>Prerequisites</h1>
<p>As shown in the introduction section, there are many moving peices to this 
demo, so there are quite naturally a few dependencies. I did try to get it to 
work in Docker for you all, however I found that I still needed to create 
external scripts to orchestrate it all anyway. In the end I just went with 
downloading stuff as I will specify, and then giving a single PowerShell script 
to run most stuff, apart from 2 Scala projects.</p>
<p>This is the list of stuff you will need in order to run this code:</p>
<p>This has all been developed on Windows, so these instructions are all about 
how to get stuff working on Windows<br><br>- MongoDB :
<a href="https://www.mongodb.com/dr/fastdl.mongodb.org/win32/mongodb-win32-x86_64-2008plus-ssl-3.4.6-signed.msi/download" target="_blank">
https://www.mongodb.com/dr/fastdl.mongodb.org/win32/mongodb-win32-x86_64-2008plus-ssl-3.4.6-signed.msi/download</a><br>
- Confluence Platform 3.3.0 Open Source :
<a href="http://packages.confluent.io/archive/3.3/confluent-oss-3.3.0-2.11.zip" target="_blank">
http://packages.confluent.io/archive/3.3/confluent-oss-3.3.0-2.11.zip</a><br>- 
SBT<br>- Java 8 SDK<br>- Webpack<br>- Node.Js<br>- NPM<br>- IntelliJ IDEA v17.0 
community<br>- PowerShell</p>
<p>Once you have downloaded all of this you will need to do a few things in 
order to run it nicely on Windows, so these instructions are all about how to 
get stuff working on Windows<br><br>- Download the dependencies above <span style="background-color:yellow; border:1px black solid">(Keep a 
note of where you downloaded them as you will need them here and later)</span><br>- 
Replace the official <span style="background-color:yellow; border:1px black solid">YOUR extract location</span>\confluent-3.3.0\bin\windows BAT files with the ones found 
here :
<a href="https://github.com/renukaradhya/confluentplatform/tree/master/bin/windows" target="_blank">
https://github.com/renukaradhya/confluentplatform/tree/master/bin/windows</a><br>
- Modify the <span style="background-color:yellow; border:1px black solid">YOUR extract location</span>\confluent-3.3.0\etc\kafka\zookeeper.properties file to change the 
<code>dataDir </code>to something like <code>dataDir=c:/temp/zookeeper</code><br>- Modify the 
<span style="background-color:yellow; border:1px black solid">YOUR extract location</span>\confluent-3.3.0\etc\kafka\server.properties file to uncomment the line 
<code>delete.topic.enable=true</code><br>- Modify the 
<span style="background-color:yellow; border:1px black solid">YOUR extract location</span>\confluent-3.3.0\etc\kafka\server.properties file file to change the 
<code>log.dirs</code> to <code>log.dirs=c:/temp/kafka-logs</code></p>
<p>You will need to remember some of these paths for the next section too, so 
just be mindful that you may have to edit the PowerShell script later with some 
new paths</p>
<h1>How do I run all this stuff?</h1>
<p>There are quite a few moving peices to this app, and they all need to be 
running in order for it to all work together.</p>


<strong>1. Update node.js dependencies</strong>
<p>Make sure you have Node.Js installed, and make sure NPM is installed too, also ensure that webpack is globally installed</p>
<p>Open command line and change to the <code>MadCapIdea\PlayBackEndApi\FrontEndWebSite\</code> folder and run 
<code>npm install</code></p>
<ul>
<li>now run <code>webpack </code>from same folder</li>
</ul>

<strong>2. Kafka/Zookeeper etc etc</strong>
<p>You can run the following powershell script to get all the pre-requistites up and running (assuming you have downloaded them all)
</p>
<ul>
<li>Open PowerShell command line and change to the <code>PowerShellProject\PowerShellProject\</code> folder and run 
<code>.\RunPipeline.ps1</code></li>
</ul>

<strong>3. Play application</strong>
<ul>
<li>Open the SBT/Scala project inside IntelliJ IDEA (you will need the SBT plugin, and Java8 installed on your machine).</li>
<li>Open this folder <code>MadCapIdea\PlayBackEndApi </code>and run it.You may need to create a run time configuration</li>
</ul>


<strong>4. Kafka Streams application</strong>
<ul>
<li>Open the SBT/Scala project inside IntelliJ IDEA (you will need the SBT plugin, and Java8 installed on your machine). </li>
<li>Open this folder <code>MadCapIdea\KafkaStreams</code> and run it.You may need to create a run time configuration 
where you point to this main class <code>RatingStreamProcessingApp</code></li>
</ul>

<strong>5. React</strong>
<ul>
<li>Open a browser navigate to <code>http://localhost:9000</code>, and register some users both passenger/driver</li>
</ul>



<p>I normally follow this set of steps afterwards</p>
<ul>
<li>open a tab, login as a passenger that I had created</li>
<li>go to the "create job" page, click the map, push the "create job" button</li>
<li>open a NEW tab, login as a new driver, go to the "view job" page</li>
<li>on the 1st tab (passenger) click the map to push passenger position to driver</li>
<li>on the 2nd tab (driver) click the map to push driver position to passenger</li>
<li>repeat last 4 steps for additonal driver</li>
<li>on client tab pick driver to accept, click accept button</li>
<li>complete the job from client tab, give driver rating</li>
<li>complete the job from paired driver tab, give passenger rating</li>
<li>go to "view rating" page, should see ratings</li>

</ul>








<h1>&nbsp;</h1>
<h1>Known issues</h1>
<p>The following are known issues</p>
<ul>
	<li>One a driver an passenger become paired, the position updates from 
	either are no longer reflected. I am sure this would boil down to a single 
	JavaScript method that needs updating in the ViewJob.tsx file. However I 
	just kind of got to the end of a very long road (I have been writing about 
	this on an off for 6 months of train rides) and was just happy that I got 
	99% of the stuff done, and just thought you know what, the app as it is now 
	demonstrates everything I set out to do, so I&#39;m ok with one known issue</li>
</ul>
<h1>Some basics</h1>
<p>Before we dive into the actual code for the app (and there is quite a bit of 
it), I just thought it may be good to go over some of the individual building 
blocks that make up the app as a whole first, the next few sections will do 
that.</p>
<h2>What is Kafka?</h2>
<p><strong>Overview</strong></p>
<p><em>Apache Kafka is an open-source stream processing platform developed by 
the Apache Software Foundation written in Scala and Java. The project aims to 
provide a unified, high-throughput, low-latency platform for handling real-time 
data feeds. Its storage layer is essentially a &quot;massively scalable pub/sub 
message queue architected as a distributed transaction log,&quot; making it highly 
valuable for enterprise infrastructures to process streaming data. Additionally, 
Kafka connects to external systems (for data import/export) via Kafka Connect 
and provides Kafka Streams, a Java stream processing library.<br><br>The design 
is heavily influenced by transaction logs.</em></p>
<p><strong>Apache Kafka Architecture</strong></p>
<p><em>Kafka stores messages which come from arbitrarily many processes called 
&quot;producers&quot;. The data can thereby be partitioned in different &quot;partitions&quot; 
within different &quot;topics&quot;. Within a partition the messages are indexed and 
stored together with a timestamp. Other processes called &quot;consumers&quot; can query 
messages from partitions. Kafka runs on a cluster of one or more servers and the 
partitions can be distributed across cluster nodes.</em></p>
<p><em>Apache Kafka efficiently processes the real-time and streaming data when 
used along with Apache Storm, Apache HBase and Apache Spark. Deployed as a 
cluster on multiple servers, Kafka handles its entire publish and subscribe 
messaging system with the help of four APIs, namely, producer API, consumer API, 
streams API and connector API. Its ability to deliver massive streams of message 
in a fault-tolerant fashion has made it replace some of the conventional 
messaging systems like JMS, AMQP, etc.</em></p>
<p><em>The major terms of Kafka&#39;s architecture are topics, records, and brokers. 
Topics consist of stream of records holding different information. On the other 
hand, Brokers are responsible for replicating the messages. There are four major 
APIs in Kafka:The major terms of Kafka&#39;s architecture are topics, records, and 
brokers. Topics consist of stream of records holding different information. On 
the other hand, Brokers are responsible for replicating the messages. There are 
four major APIs in Kafka:</em></p>
<ul>
	<li><em>Producer API - Permits the applications to publish streams of 
	records. </em><strong>(covered in this article)</strong></li>
	<li><em>Consumer API - Permits the application to subscribe to the topics 
	and processes the stream of records. </em><strong>(covered in this article)</strong></li>
	<li><em>Streams API – This API converts the input streams to output and 
	produces the result. </em><strong>(covered in this article)</strong></li>
	<li><em>Connector API – Executes the reusable producer and consumer APIs 
	that can link the topics to the existing applications. </em><strong>(not 
	covered in this article)</strong></li>
</ul>
<p><img alt="" height="298" src="kafka1.png" width="400"></p>
<p>&nbsp;</p>
<p><strong>Anatomy of a Kafka Topic</strong></p>
<p><strong>Offset</strong> : messages in the partitions are each assigned a 
unique (per partition) and sequential Id, called the &quot;offset&quot;. The &quot;offset&quot; is 
tracked by consumers, where each consumer tracks via (offset, partition, topic) 
tuples</p>
<p><img alt="" height="245" src="kafka2.png" width="462"></p>
<p><strong>Consumer Groups</strong></p>
<p>Consumers label themselves with a consumer group name, and each record 
published to a topic is delivered to one consumer instance within each 
subscribing consumer group. Consumer instances can be in separate processes or 
on separate machines.<br><br>
<img alt="" height="376" src="kafka3.png" width="630"></p>
<p>If all the consumer instances have the same consumer group, then the records 
will effectively be load balanced over the consumer instances.<br><br>If all the 
consumer instances have different consumer groups, then each record will be 
broadcast to all the consumer processes</p>
<p><img alt="" height="252" src="kafka4.png" width="474"></p>
<p>A two server Kafka cluster hosting four partitions (P0-P3) with two consumer 
groups. Consumer group A has two consumer instances and group B has four.</p>
<p>&nbsp;</p>
<p><strong>Kafka Performance</strong></p>
<p><em>Due to its widespread integration into enterprise-level infrastructures, 
monitoring Kafka performance at scale has become an increasingly important 
issue. Monitoring end-to-end performance requires tracking metrics from brokers, 
consumer, and producers, in addition to monitoring ZooKeeper which is used by 
Kafka for coordination among consumers</em></p>
<p><a href="https://en.wikipedia.org/wiki/Apache_Kafka">
https://en.wikipedia.org/wiki/Apache_Kafka</a> up on date 02/01/18</p>
<p>&nbsp;</p>
<h2>What is Kafka Streams?</h2>
<p><em>The Streams API of Apache Kafka, available through a Java library, can be 
used to build highly scalable, elastic, fault-tolerant, distributed applications 
and microservices. First and foremost, the Kafka Streams API allows you to 
create real-time applications that power your core business. It is the easiest 
yet the most powerful technology to process data stored in Kafka. It builds upon 
important concepts for stream processing such as efficient management of 
application state, fast and efficient aggregations and joins, properly 
distinguishing between event-time and processing-time, and seamless handling of 
late-arriving and out-of-order data.</em></p>
<p><em>A unique feature of the Kafka Streams API is that the applications you 
build with it are normal Java applications. These applications can be packaged, 
deployed, and monitored like any other Java application – there is no need to 
install separate processing clusters or similar special-purpose and expensive 
infrastructure!</em></p>
<p><img alt="" height="433" src="kafkastream1.png" width="630"><em><br></em><br>
<em>An application that uses the Kafka Streams API is a normal Java application. 
Package, deploy, and monitor it like you would do for any other Java 
application. Even so, your application will be highly scalable, elastic, and 
fault-tolerant.</em></p>
<p><a href="https://docs.confluent.io/current/streams/introduction.html">
https://docs.confluent.io/current/streams/introduction.html</a> up on date 
02/01/18</p>
<p>So that is what the official docs say about it,. here is my take on it</p>
<p>Kafka Streams is an additional API on top of Kafka that allows you to perform 
many aggregate and filtering, time based windowing operations over the incoming 
messages, that can either be stored to an internal database key-value 
representation known as a KTable which uses a state store (based on
<a href="http://rocksdb.org/" target="_blank">RocksDB</a>). Or you may choose to 
push the transformed stream values out to a new output topic. </p>
<p>You can perform complex stream processing, merge streams, and also store 
accumulated stream state.</p>
<p>It is a an AWESOME bit of kit</p>
<h2>What is Play?</h2>
<p>The Play Framework is a Scala based MVC (model view controller) type web 
application framework. As such it has in built mechanisms for things typical of 
a MVC web framework (certainly if you have done any ASP MVC . NET you would find 
it very familiar).</p>
<p>So we have the typical MVC concerns covered by the
<a href="https://www.playframework.com/documentation/2.5.x/Home" target="_blank">
Play Framework</a></p>
<ul>
	<li>Controllers</li>
	<li>Actions</li>
	<li>Routing</li>
	<li>Model binding</li>
	<li>JSON support</li>
	<li>View engine</li>
</ul>
<p>Thing is I will not be doing any actual HTML in the <a href="https://www.playframework.com/documentation/2.5.x/Home" target="_blank">
Play Framework</a> back end code, I want to do all of that using the previously covered webpack/typescript/react starter code I have shown so far. Rather I will be using the Play Framework as a API backend, where we will simply be using various controllers as endpoint to accept/serve JSON, and Event streamed data. All the actual front end work/routing will be done via webpack and React.
</p>
<p>There are still some very appealing parts in Play that I did want to make use of, such as:</p>
<ul>
<li>It is Scala, which means when I come to integrate Kafka / Kafka Streams it will be ready to do so</li>
<li>It uses Akka which I wanted to use. I also want to use Akka streams, which Play also supports</li>
<li>Play controllers lend themselves quite nicely to being able to create a fairly simple REST API</li>
<li>It can be used fairly easily to serve static files (think of these as the final artifacts that come out of the webpack generation pipeline). So things like minimized CSS / JS etc etc</li>
</ul>
<p>So hopefully you can see that using Play Framework still made a lot of sense, even if we will only end up using 1/2 of what it has to offer. To be honest the idea of using controllers for a REST API is something that is done in ASP MVC .NET all time either by using of actual controllers or by using the WebApi.</p>
<p>Ok so now that we know what we will be using Play Framework for, how about we dive into the code for this post.</p>
<p><strong>Play Framework Basics</strong></p>
<p>Lets start by looking at the bare bones structure of a Play Framework application, which looks like this (I am using IntelliJ IDEA as my IDE)</p>



<p><img alt="" height="377" src="play1.png" width="400"></p>
<p>Lets talk a bit about each of these folders</p>
<p><strong>app</strong></p>
<p>This folder would hold controllers/views (I have added the Entities folder there that is not part of a Play Framework application requirements). Inside the controllers folder you would find controllers, and inside the views folder you would find views. For the final app there will be no views folder, I simply kept that in this screenshot to talk about what a standard Play Framework application looks like</p>

<p><strong>conf</strong></p>
<p>This folder contains the configuration for the Play Framework application. This would include the special routes file, and any other application specific configuration would might have.</p>
<p>Lets just spend a minute having a look at the Play Framework routes file, which you can read more about here : https://www.playframework.com/documentation/2.5.x/ScalaRouting</p>
<p>The routes file has its own DSL, that is responsible for matching a give route with a controller + controller action. The controller action that matches the route is ultimately responsible for servicing the http request. I think the DSL shown in routes file below is pretty self explanatory with perhaps the exception of the assets based routes.</p>
<p>All assets based http requests (ie ones that start with /assets for example http://localhost:9000/assets/images/favicon.png would actually be routed through to a special controller called Assets. You dont see any code for this one, its part of the Play Framework application codebase. This special Assets inbuilt play controller is responsible for serving up static data files which it expects to find in the public folder. So for example our initial request of http://localhost:9000/assets/images/favicon.png would get translated into this file (relative path from project root) /public/images/favicon.png. As I say this is handled for you by the special Assets built in controller.</p>
<p>The only other funky part to the Assets based route is that it uses a *file in its route. Which essentially boils down to the play framework being able match a multi-part path. Which we actually just saw with the example above http://localhost:9000/assets/images/favicon.png , see how that contains not only the file name, but also a directory of images. The Assets controller + routing is able to deal with that path just fine.</p>
<pre>
# Routes
# This file defines all application routes (Higher priority routes first)
# ~~~~

# Home page

GET        /                                   controllers.HomeController.index()

GET        /scala/comet/liveClock              controllers.ScalaCometController.streamClock()
GET        /scala/comet/kick                   controllers.ScalaCometController.kickRandomTime()

# Map static resources from the /public folder to the /assets URL path
GET        /assets/*file                       controllers.Assets.at(path="/public", file)
</pre>
<p>Ok so moving on to the rest of the standard folders that come with a Play Framework application</p>
<p><strong>public</strong></p>
<p>This is where you will need to put any static content that you wish to be served. Obviously views (if you use that part of play) will be within in the app/views folder. Like I say I am not using the views aspect of Play so you will not be seeing any views in my views folder. I instead want to let webpack et all generate my routing, web page etc etc. I do however want to serve bundles so later on I will be showing you how my webpack generated bundles fit in with the Play Framework ecco system.</p>
<p><strong>target</strong></p>
<p>Since this is a scala based project we get the standard scala based folders, and target is one of them, that has the generated/compiled code in it.</p>
<p><strong>SBT</strong></p>
<p>It is worth pointing out that my Play Framework application is an SBT based project, as such there is an SBT aspect to it, which largely boils down to these files</p>
<p><strong>Project [root-build] / plugs.sbt file</strong></p>
<p>This file adds Play as a plugin for the SBT project</p>
<pre>
// The Lightbend repository
resolvers += Resolver.typesafeRepo("releases")

// Use the Play sbt plugin for Play projects
addSbtPlugin("com.typesafe.play" % "sbt-plugin" % "2.5.14")
</pre>
<p><strong>build.sbt</strong></p>
<p>This is the main SBT build file for the project. This is where all our external dependencies are brought in etc etc (standard SBT stuff)</p>
<pre>
import play.sbt._
import sbt.Keys._
import sbt._

name := "play-streaming-scala"

version := "1.0-SNAPSHOT"

scalaVersion := "2.11.11"

lazy val root = (project in file(".")).enablePlugins(play.sbt.PlayScala)

javacOptions ++= Seq("-source", "1.8", "-target", "1.8", "-Xlint")

initialize := {
  val _ = initialize.value
  if (sys.props("java.specification.version") != "1.8")
    sys.error("Java 8 is required for this project.")
}
</pre>
<p>So I think that covers the basics of a standard Play Framework application, the remainder of this article will cover the actual code for the demo project, where we will dive into routes/controllers etc etc</p>




<h2>What is WebPack?</h2>
<h2>What is React?</h2>
<h2>What is TypeScript?</h2>
<h1>&nbsp;</h1>
<h1>The app</h1>
<h2>The &quot;Index&quot; page</h2>
<h2>Registration workflow</h2>
<h2>Login workflow</h2>
<h2>CreateJob workflow</h2>
<h2>ViewJob workflow</h2>
<h2>ViewRating workflow</h2>
<h1>Conclusion</h1>
<p>This was certainly a challenging thing to write, and I am honestly pleased that I got it done, I have had a really good time writing this. And it has been a great project for self improvement, and 
I would recommend this type of thing as a great use of time. Go on find yourself 
a pet project</p>



